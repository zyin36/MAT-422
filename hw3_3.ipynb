{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTDFgLhemljEqrnW+tVAeZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zyin36/MAT-422/blob/main/hw3_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.math.ucla.edu/~lvese/273.1.06f/Summary.pdf\n",
        "https://www.math.uci.edu/~chenlong/110/110A-Conditions.pdf\n",
        "\n",
        "**Necessary and Sufficient Conditions of *Local* Minimizers** <br/>\n",
        "Local minimizer: $x*: f(x_*) ‚â§ f(x) \\ ‚àÄx‚àà \\ B_œµ(x_*) - \\{x_*\\}$ <br/>\n",
        "Strict local minimizer: $x*: f(x_*) \\lt f(x) \\ ‚àÄx‚àà \\ B_œµ(x_*) - \\{x_*\\}$ <br/>\n",
        "where $œµ > 0.$\n",
        "<br/><br/>\n",
        "First-order necessary condition: If $x_*$ is a local minimizer, then $‚àáf(x_*) = 0$\n",
        "<br/>\n",
        "Second-order necessary condition: If $x_*$ is a local minimizer, then $H_f(x_*)$ is PSD.\n",
        "<br/>\n",
        "**Convex Sets and Functions** <\\br>\n",
        "\n",
        "\n",
        "**Gradient Descent**\n",
        "\n",
        "Unit vector of Steepest Descent at $x_0$: $ùêØ_* = -\\frac{‚àáf(x_0)}{||‚àáf(x_0)||}$"
      ],
      "metadata": {
        "id": "tSLKZuvHnksm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYaWNgEVnWSw",
        "outputId": "3d9e58df-e5d4-42fa-8057-649bd17aad17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_0:  [1 1 1]\n",
            "Steepest descent: [-2. -2. -2.]\n"
          ]
        }
      ],
      "source": [
        "import autograd.numpy as np\n",
        "from autograd import grad\n",
        "\n",
        "# Function of a sphere\n",
        "def f(x):\n",
        "    return np.sum(x**2, dtype=float)\n",
        "\n",
        "# Define the point at which to evaluate the gradient\n",
        "x_0 = np.array([1,1,1])\n",
        "\n",
        "# Calculate the gradient of f\n",
        "grad_f = grad(f)\n",
        "\n",
        "# steepest descent\n",
        "gradient_at_x_0 = -grad_f(x_0)\n",
        "\n",
        "print(\"x_0: \", x_0)\n",
        "print(\"Steepest descent:\", gradient_at_x_0)\n"
      ]
    }
  ]
}